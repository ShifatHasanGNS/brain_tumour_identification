{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 16782,
     "status": "ok",
     "timestamp": 1742038263863,
     "user": {
      "displayName": "Md. Shifat Hasan",
      "userId": "07131367091968026409"
     },
     "user_tz": -360
    },
    "id": "3Zp9r7SderFg"
   },
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "import os\n",
    "from typing import List\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import psutil\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, callbacks, backend, layers, Sequential\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1742038267987,
     "user": {
      "displayName": "Md. Shifat Hasan",
      "userId": "07131367091968026409"
     },
     "user_tz": -360
    },
    "id": "79iDT5B3p0Mm"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "TEXT_MAX_LENGTH = 512\n",
    "NUM_CLASSES = 4\n",
    "CLASS_NAMES = ['glioma_tumor', 'meningioma_tumor', 'pituitary_tumor', 'no_tumor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1742038269479,
     "user": {
      "displayName": "Md. Shifat Hasan",
      "userId": "07131367091968026409"
     },
     "user_tz": -360
    },
    "id": "IwYY21xBc9Gm"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../Data'\n",
    "MODELS_DIR = '../Models'\n",
    "LOG_DIR = '../Logs'\n",
    "BENCHMARK_DIR = '../Metrics/Benchmarks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1742038271400,
     "user": {
      "displayName": "Md. Shifat Hasan",
      "userId": "07131367091968026409"
     },
     "user_tz": -360
    },
    "id": "5KsZOhqkeRGA",
    "outputId": "f8dcebcf-8401-49dc-ad37-83431e384c67"
   },
   "outputs": [],
   "source": [
    "strategy = tf.distribute.get_strategy()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1742038273222,
     "user": {
      "displayName": "Md. Shifat Hasan",
      "userId": "07131367091968026409"
     },
     "user_tz": -360
    },
    "id": "-bIuyxP5epYL"
   },
   "outputs": [],
   "source": [
    "class ModelBenchmark:\n",
    "    def __init__(self, model_name: str):\n",
    "        self.model_name = model_name\n",
    "        self.metrics = {\n",
    "            'training_time': 0,\n",
    "            'inference_time': 0,\n",
    "            'memory_usage': 0,\n",
    "            'model_size': 0,\n",
    "            'accuracy': 0,\n",
    "            'precision': 0,\n",
    "            'recall': 0,\n",
    "            'f1_score': 0,\n",
    "            'auc': 0,\n",
    "            'confusion_matrix': None,\n",
    "            'class_wise_metrics': {},\n",
    "            'training_history': None\n",
    "        }\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "\n",
    "    def start_training_timer(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def end_training_timer(self):\n",
    "        if self.start_time is not None:\n",
    "            self.end_time = time.time()\n",
    "            self.metrics['training_time'] = self.end_time - self.start_time\n",
    "        else:\n",
    "            print(\"Warning: Training timer was not started\")\n",
    "            self.metrics['training_time'] = 0\n",
    "\n",
    "    def measure_inference_time(self, model: Model, dataset: tf.data.Dataset):\n",
    "        try:\n",
    "            inference_times = []\n",
    "            for x, _ in dataset.take(100):\n",
    "                start = time.time()\n",
    "                model.predict(x, verbose=0)\n",
    "                inference_times.append(time.time() - start)\n",
    "            self.metrics['inference_time'] = np.mean(inference_times)\n",
    "        except Exception as e:\n",
    "            print(f\"Error measuring inference time: {e}\")\n",
    "            self.metrics['inference_time'] = 0\n",
    "\n",
    "    def measure_memory_usage(self):\n",
    "        try:\n",
    "            process = psutil.Process()\n",
    "            self.metrics['memory_usage'] = process.memory_info().rss / 1024 / 1024\n",
    "        except ImportError:\n",
    "            print(\"Warning: psutil not available for memory measurement\")\n",
    "            self.metrics['memory_usage'] = 0\n",
    "        except Exception as e:\n",
    "            print(f\"Error measuring memory usage: {e}\")\n",
    "            self.metrics['memory_usage'] = 0\n",
    "\n",
    "    def calculate_model_size(self, model_path: str):\n",
    "        try:\n",
    "            if os.path.exists(model_path):\n",
    "                size_bytes = os.path.getsize(model_path)\n",
    "                self.metrics['model_size'] = size_bytes / (1024 * 1024)\n",
    "            else:\n",
    "                print(f\"Warning: Model file not found at {model_path}\")\n",
    "                self.metrics['model_size'] = 0\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating model size: {e}\")\n",
    "            self.metrics['model_size'] = 0\n",
    "\n",
    "    def update_metrics(self, history: callbacks.History,\n",
    "                      test_results: List[float],\n",
    "                      cm: np.ndarray,\n",
    "                      class_report: str):\n",
    "        try:\n",
    "            self.metrics['training_history'] = history.history\n",
    "            if len(test_results) >= 5:\n",
    "                self.metrics['accuracy'] = test_results[1]\n",
    "                self.metrics['precision'] = test_results[2]\n",
    "                self.metrics['recall'] = test_results[3]\n",
    "                self.metrics['auc'] = test_results[4]\n",
    "            else:\n",
    "                print(\"Warning: Insufficient test results\")\n",
    "\n",
    "            self.metrics['confusion_matrix'] = cm.tolist() if cm is not None else None\n",
    "\n",
    "            if class_report:\n",
    "                report_lines = class_report.split('\\n')\n",
    "                for line in report_lines[2:-3]:\n",
    "                    if line.strip():\n",
    "                        parts = line.split()\n",
    "                        if len(parts) >= 5:\n",
    "                            class_name = parts[0]\n",
    "                            self.metrics['class_wise_metrics'][class_name] = {\n",
    "                                'precision': float(parts[1]),\n",
    "                                'recall': float(parts[2]),\n",
    "                                'f1_score': float(parts[3]),\n",
    "                                'support': int(parts[4])\n",
    "                            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating metrics: {e}\")\n",
    "\n",
    "    def save_metrics(self, output_dir: str):\n",
    "        try:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            output_path = os.path.join(output_dir, f'{self.model_name}_metrics.json')\n",
    "            with open(output_path, 'w') as f:\n",
    "                json.dump(self.metrics, f, indent=4)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving metrics: {e}\")\n",
    "\n",
    "    def plot_comparison(self, other_benchmark: 'ModelBenchmark', output_dir: str):\n",
    "        try:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            if not self.metrics['training_history'] or not other_benchmark.metrics['training_history']:\n",
    "                print(\"Warning: Missing training history for comparison\")\n",
    "                return\n",
    "\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            metrics = ['accuracy', 'precision', 'recall', 'auc']\n",
    "            for i, metric in enumerate(metrics, 1):\n",
    "                plt.subplot(2, 2, i)\n",
    "                if metric in self.metrics['training_history']:\n",
    "                    plt.plot(self.metrics['training_history'][metric],\n",
    "                            label=f'{self.model_name} (Training)')\n",
    "                    plt.plot(self.metrics['training_history'][f'val_{metric}'],\n",
    "                            label=f'{self.model_name} (Validation)')\n",
    "                if metric in other_benchmark.metrics['training_history']:\n",
    "                    plt.plot(other_benchmark.metrics['training_history'][metric],\n",
    "                            label=f'{other_benchmark.model_name} (Training)')\n",
    "                    plt.plot(other_benchmark.metrics['training_history'][f'val_{metric}'],\n",
    "                            label=f'{other_benchmark.model_name} (Validation)')\n",
    "                plt.title(f'{metric.capitalize()} Comparison')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel(metric.capitalize())\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, 'training_metrics_comparison.png'))\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting comparison: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1742038274685,
     "user": {
      "displayName": "Md. Shifat Hasan",
      "userId": "07131367091968026409"
     },
     "user_tz": -360
    },
    "id": "lXi95k1Ce27S"
   },
   "outputs": [],
   "source": [
    "def process_text(text_path):\n",
    "    try:\n",
    "        if not os.path.exists(text_path):\n",
    "            print(f\"Warning: Text file not found at {text_path}\")\n",
    "            return np.zeros(TEXT_MAX_LENGTH, dtype=np.int32)\n",
    "\n",
    "        with open(text_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read().strip()\n",
    "            if not text:\n",
    "                print(f\"Warning: Empty text file at {text_path}\")\n",
    "                return np.zeros(TEXT_MAX_LENGTH, dtype=np.int32)\n",
    "\n",
    "        encoded = tokenizer.encode(text)[:TEXT_MAX_LENGTH]\n",
    "        return np.pad(\n",
    "            encoded,\n",
    "            (0, max(0, TEXT_MAX_LENGTH - len(encoded))),\n",
    "            'constant'\n",
    "        ).astype(np.int32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text file {text_path}: {e}\")\n",
    "        return np.zeros(TEXT_MAX_LENGTH, dtype=np.int32)\n",
    "\n",
    "preprocessing_model = keras.Sequential([\n",
    "    keras.layers.Normalization(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        variance=[0.229**2, 0.224**2, 0.225**2]\n",
    "    )\n",
    "], name=\"preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1742038275690,
     "user": {
      "displayName": "Md. Shifat Hasan",
      "userId": "07131367091968026409"
     },
     "user_tz": -360
    },
    "id": "1QzTCDGWe-KN"
   },
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    try:\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        backend.clear_session()\n",
    "        print(\"Memory cleared successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error clearing memory: {e}\")\n",
    "\n",
    "def create_datasets(data_dir, validation_split=0.2, use_text=True):\n",
    "    try:\n",
    "        if not os.path.exists(data_dir):\n",
    "            raise ValueError(f\"Data directory not found: {data_dir}\")\n",
    "\n",
    "        clear_memory()\n",
    "\n",
    "        common_args = {\n",
    "            'labels': 'inferred',\n",
    "            'label_mode': 'categorical',\n",
    "            'class_names': CLASS_NAMES,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'image_size': (IMAGE_SIZE, IMAGE_SIZE),\n",
    "            'seed': 42\n",
    "        }\n",
    "\n",
    "        # Create datasets with file paths\n",
    "        train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "            os.path.join(data_dir, 'train'),\n",
    "            shuffle=True,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "            os.path.join(data_dir, 'test'),\n",
    "            shuffle=False,\n",
    "            **common_args\n",
    "        )\n",
    "\n",
    "        def preprocess_images(images, labels):\n",
    "            images = tf.cast(images, tf.float32) / 255.0\n",
    "            mean = tf.constant([0.485, 0.456, 0.406])\n",
    "            std = tf.constant([0.229, 0.224, 0.225])\n",
    "            images = (images - mean) / std\n",
    "            return images, labels\n",
    "\n",
    "        train_ds = train_ds.map(preprocess_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        test_ds = test_ds.map(preprocess_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "        val_ds = None\n",
    "        if validation_split > 0:\n",
    "            val_size = int(validation_split * len(train_ds))\n",
    "            val_ds = train_ds.take(val_size)\n",
    "            train_ds = train_ds.skip(val_size)\n",
    "\n",
    "        if use_text:\n",
    "            def process_text_features(image_paths):\n",
    "                text_paths = [p.replace('.jpg', '.txt') for p in image_paths]\n",
    "                text_features = np.zeros((len(image_paths), TEXT_MAX_LENGTH), dtype=np.int32)\n",
    "                for i, text_path in enumerate(text_paths):\n",
    "                    if os.path.exists(text_path):\n",
    "                        text_features[i] = process_text(text_path)\n",
    "                return text_features\n",
    "\n",
    "            def add_text_features_to_batch(images, labels):\n",
    "                return (images, tf.zeros([tf.shape(images)[0], TEXT_MAX_LENGTH], dtype=tf.int32)), labels\n",
    "\n",
    "            train_ds = train_ds.map(add_text_features_to_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            if val_ds:\n",
    "                val_ds = val_ds.map(add_text_features_to_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            test_ds = test_ds.map(add_text_features_to_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "        train_ds = train_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "        test_ds = test_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "        if val_ds:\n",
    "            val_ds = val_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        return {'train': train_ds, 'validation': val_ds, 'test': test_ds}\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating datasets: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1742038276621,
     "user": {
      "displayName": "Md. Shifat Hasan",
      "userId": "07131367091968026409"
     },
     "user_tz": -360
    },
    "id": "sS13hx8RfCP-"
   },
   "outputs": [],
   "source": [
    "class CrossAttentionLayer(layers.Layer):\n",
    "    def __init__(self, num_heads, key_dim):\n",
    "        super(CrossAttentionLayer, self).__init__()\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)\n",
    "        self.layer_norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout = layers.Dropout(0.1)\n",
    "\n",
    "    def call(self, x, y, training=False):\n",
    "        attn_output = self.mha(x, y, y, training=training)\n",
    "        x = self.layer_norm1(x + self.dropout(attn_output, training=training))\n",
    "\n",
    "        attn_output = self.mha(y, x, x, training=training)\n",
    "        y = self.layer_norm2(y + self.dropout(attn_output, training=training))\n",
    "\n",
    "        return x, y\n",
    "\n",
    "class BrainTumorModel(Model):\n",
    "    def __init__(self, num_classes, use_text=True):\n",
    "        super(BrainTumorModel, self).__init__()\n",
    "        self.use_text = use_text\n",
    "\n",
    "        self.image_conv = Sequential([\n",
    "            layers.Conv2D(32, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3, activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.Dropout(0.5)\n",
    "        ])\n",
    "\n",
    "        self.text_embedding = layers.Embedding(10000, 128)\n",
    "        self.text_lstm = layers.LSTM(256, return_sequences=True)\n",
    "        self.text_conv = layers.Conv1D(256, 3, activation='relu')\n",
    "        self.text_pool = layers.GlobalMaxPooling1D()\n",
    "\n",
    "        self.cross_attention = CrossAttentionLayer(num_heads=8, key_dim=64)\n",
    "\n",
    "        self.fusion = layers.Dense(512, activation='relu')\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "        self.classifier = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        images, texts = inputs\n",
    "\n",
    "        image_features = self.image_conv(images, training=training)\n",
    "\n",
    "        if self.use_text:\n",
    "            text_embeddings = self.text_embedding(texts)\n",
    "            text_features = self.text_lstm(text_embeddings, training=training)\n",
    "            text_features = self.text_conv(text_features, training=training)\n",
    "            text_features = self.text_pool(text_features)\n",
    "\n",
    "            image_features = tf.expand_dims(image_features, axis=1)\n",
    "            text_features = tf.expand_dims(text_features, axis=1)\n",
    "\n",
    "            image_features, text_features = self.cross_attention(\n",
    "                image_features, text_features, training=training\n",
    "            )\n",
    "\n",
    "            combined = tf.concat([image_features, text_features], axis=-1)\n",
    "            combined = tf.squeeze(combined, axis=1)\n",
    "        else:\n",
    "            combined = image_features\n",
    "\n",
    "        x = self.fusion(combined)\n",
    "        x = self.dropout(x, training=training)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1742038277510,
     "user": {
      "displayName": "Md. Shifat Hasan",
      "userId": "07131367091968026409"
     },
     "user_tz": -360
    },
    "id": "K6PCCvEnf5m8"
   },
   "outputs": [],
   "source": [
    "def create_model(use_text=True, num_classes=NUM_CLASSES):\n",
    "    try:\n",
    "        with strategy.scope():\n",
    "            activation = 'relu'\n",
    "            norm_layer = keras.layers.BatchNormalization\n",
    "\n",
    "            try:\n",
    "                base_model = keras.applications.MobileNetV3Small(\n",
    "                    include_top=False,\n",
    "                    weights='imagenet',\n",
    "                    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "                    minimalistic=True\n",
    "                )\n",
    "                print(\"Using MobileNetV3Small as base model\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading MobileNetV3Small: {e}\")\n",
    "                print(\"Falling back to MobileNetV2\")\n",
    "                base_model = keras.applications.MobileNetV2(\n",
    "                    include_top=False,\n",
    "                    weights='imagenet',\n",
    "                    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "                    alpha=0.75  # Use a smaller version\n",
    "                )\n",
    "\n",
    "            for layer in base_model.layers[:-4]:\n",
    "                layer.trainable = False\n",
    "\n",
    "            image_input = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), name='image_input')\n",
    "            x = base_model(image_input, training=False)\n",
    "            x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "            x = keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "            image_features = keras.layers.Dense(256, activation=activation,\n",
    "                                             kernel_regularizer=keras.regularizers.l2(1e-4))(x)\n",
    "\n",
    "            if use_text:\n",
    "                text_input = keras.Input(shape=(TEXT_MAX_LENGTH,), name='text_input')\n",
    "                \n",
    "                z = keras.layers.Embedding(tokenizer.n_vocab, 128,\n",
    "                                        embeddings_regularizer=keras.regularizers.l2(1e-4))(text_input)\n",
    "                \n",
    "                z = keras.layers.SeparableConv1D(256, 5, padding='same', activation=activation)(z)\n",
    "                z = norm_layer()(z)\n",
    "                z = keras.layers.MaxPooling1D(2)(z)\n",
    "                z = keras.layers.Dropout(0.3)(z)\n",
    "\n",
    "                z = keras.layers.SeparableConv1D(128, 3, padding='same', activation=activation)(z)\n",
    "                z = norm_layer()(z)\n",
    "                z = keras.layers.GlobalAveragePooling1D()(z)\n",
    "                text_features = keras.layers.Dropout(0.3)(z)\n",
    "\n",
    "                combined = keras.layers.Concatenate()([image_features, text_features])\n",
    "                y = keras.layers.Dense(256, activation=activation,\n",
    "                                    kernel_regularizer=keras.regularizers.l2(1e-4))(combined)\n",
    "                y = norm_layer()(y)\n",
    "                y = keras.layers.Dropout(0.4)(y)\n",
    "\n",
    "                outputs = keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                          kernel_regularizer=keras.regularizers.l2(1e-4))(y)\n",
    "                model = keras.Model(inputs=[image_input, text_input], outputs=outputs)\n",
    "            else:\n",
    "                y = keras.layers.Dense(128, activation=activation,\n",
    "                                     kernel_regularizer=keras.regularizers.l2(1e-4))(image_features)\n",
    "                y = norm_layer()(y)\n",
    "                y = keras.layers.Dropout(0.4)(y)\n",
    "\n",
    "                outputs = keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                          kernel_regularizer=keras.regularizers.l2(1e-4))(y)\n",
    "                model = keras.Model(inputs=image_input, outputs=outputs)\n",
    "\n",
    "            return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating model: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742038278224,
     "user": {
      "displayName": "Md. Shifat Hasan",
      "userId": "07131367091968026409"
     },
     "user_tz": -360
    },
    "id": "X3TC1h2nf825"
   },
   "outputs": [],
   "source": [
    "class ProgressCallback(callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(ProgressCallback, self).__init__()\n",
    "        self.epoch_times = []\n",
    "        self.start_time = None\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.start_time = time.time()\n",
    "        print(f\"\\nEpoch {epoch + 1}/{self.params['epochs']}\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.start_time is None:\n",
    "            print(\"Warning: start_time not initialized\")\n",
    "            return\n",
    "\n",
    "        epoch_time = time.time() - self.start_time\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        avg_time = np.mean(self.epoch_times)\n",
    "        remaining_epochs = self.params['epochs'] - (epoch + 1)\n",
    "        estimated_time = remaining_epochs * avg_time\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} completed in {epoch_time:.2f}s\")\n",
    "        print(f\"Estimated time remaining: {estimated_time/60:.1f} minutes\")\n",
    "\n",
    "        if logs:\n",
    "            print(\"Metrics:\")\n",
    "            for key, value in logs.items():\n",
    "                print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1742038279053,
     "user": {
      "displayName": "Md. Shifat Hasan",
      "userId": "07131367091968026409"
     },
     "user_tz": -360
    },
    "id": "tv9aIw7AhVkd"
   },
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(model, dataset):\n",
    "    try:\n",
    "        y_pred_all, y_true_all = [], []\n",
    "\n",
    "        for x, y in dataset:\n",
    "            y_pred = model.predict(x, verbose=0)\n",
    "            y_pred_all.extend(tf.argmax(y_pred, axis=1).numpy())\n",
    "            y_true_all.extend(tf.argmax(y, axis=1).numpy())\n",
    "\n",
    "        cm = confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "        report = classification_report(y_true_all, y_pred_all,\n",
    "                                    target_names=CLASS_NAMES, digits=4)\n",
    "        print(\"\\nClassification Report:\\n\")\n",
    "        print(report)\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        disp = ConfusionMatrixDisplay(\n",
    "            confusion_matrix=cm,\n",
    "            display_labels=CLASS_NAMES\n",
    "        )\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plot_path = os.path.join(BENCHMARK_DIR, 'confusion_matrix.png')\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "\n",
    "        return cm, report\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing confusion matrix: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def plot_metrics(history):\n",
    "    try:\n",
    "        metric_groups = {\n",
    "            'Accuracy Metrics': ['accuracy', 'val_accuracy', 'precision', 'val_precision', 'recall', 'val_recall'],\n",
    "            'Loss': ['loss', 'val_loss'],\n",
    "            'AUC': ['auc', 'val_auc']\n",
    "        }\n",
    "\n",
    "        for group_name, metrics in metric_groups.items():\n",
    "            available_metrics = [m for m in metrics if m in history.history]\n",
    "            if not available_metrics:\n",
    "                continue\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "\n",
    "            for metric in available_metrics:\n",
    "                plt.plot(\n",
    "                    history.history[metric],\n",
    "                    label=metric.replace('val_', 'Validation ') if 'val_' in metric\n",
    "                          else f'Training {metric}'\n",
    "                )\n",
    "\n",
    "            plt.title(f'{group_name}')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel(group_name)\n",
    "            plt.legend()\n",
    "            plt.grid(True, linestyle='--', alpha=0.5)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            plot_path = os.path.join(BENCHMARK_DIR, f'{group_name.lower().replace(\" \", \"_\")}_plot.png')\n",
    "            plt.savefig(plot_path)\n",
    "            plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting metrics: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1742038279883,
     "user": {
      "displayName": "Md. Shifat Hasan",
      "userId": "07131367091968026409"
     },
     "user_tz": -360
    },
    "id": "QMofnSf1g_KH"
   },
   "outputs": [],
   "source": [
    "def train_model(data_dir, use_text=True, resume_from=None, epochs=NUM_EPOCHS):\n",
    "    print(f\"Starting Brain Tumor Classification Training (use_text={use_text})\")\n",
    "\n",
    "    try:\n",
    "        clear_memory()\n",
    "\n",
    "        model_name = f\"model_with_text\" if use_text else \"model_without_text\"\n",
    "        benchmark = ModelBenchmark(model_name)\n",
    "\n",
    "        print(\"\\nLoading datasets...\")\n",
    "        datasets = create_datasets(data_dir, validation_split=0.2, use_text=use_text)\n",
    "        train_ds = datasets['train']\n",
    "        val_ds = datasets['validation']\n",
    "        test_ds = datasets['test']\n",
    "\n",
    "        print(f\"Training samples: {len(train_ds)}\")\n",
    "        if val_ds:\n",
    "            print(f\"Validation samples: {len(val_ds)}\")\n",
    "        print(f\"Test samples: {len(test_ds)}\")\n",
    "\n",
    "        clear_memory()\n",
    "\n",
    "        with strategy.scope():\n",
    "            model, initial_epoch = None, 0\n",
    "            if resume_from and os.path.exists(resume_from):\n",
    "                try:\n",
    "                    print(f\"\\nLoading model from checkpoint: {resume_from}\")\n",
    "                    model = keras.models.load_model(resume_from)\n",
    "                    initial_epoch = int(resume_from.split('_')[-1].split('.')[0]) if 'epoch' in resume_from else 0\n",
    "                    print(f\"Resumed from epoch {initial_epoch}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading model: {e}\")\n",
    "\n",
    "            if model is None:\n",
    "                print(\"\\nCreating new model...\")\n",
    "                model = create_model(use_text=use_text)\n",
    "                initial_epoch = 0\n",
    "\n",
    "            lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate=LEARNING_RATE,\n",
    "                decay_steps=epochs//3 * len(train_ds),\n",
    "                decay_rate=0.5,\n",
    "                staircase=True\n",
    "            )\n",
    "\n",
    "            optimizer = (\n",
    "                keras.optimizers.AdamW(learning_rate=lr_schedule, weight_decay=1e-4)\n",
    "                if hasattr(keras.optimizers, 'AdamW') else\n",
    "                keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "            )\n",
    "\n",
    "            model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy', 'Precision', 'Recall', 'AUC']\n",
    "            )\n",
    "\n",
    "        clear_memory()\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        callbacks = [\n",
    "            keras.callbacks.ModelCheckpoint(\n",
    "                filepath=os.path.join(MODELS_DIR, f'best_{model_name}.keras'),\n",
    "                save_best_only=True,\n",
    "                monitor='val_accuracy',\n",
    "                mode='max'\n",
    "            ),\n",
    "            keras.callbacks.TensorBoard(\n",
    "                log_dir=os.path.join(LOG_DIR, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "            ),\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=10,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            ProgressCallback()\n",
    "        ]\n",
    "\n",
    "        print(\"\\nStarting training...\")\n",
    "        benchmark.start_training_timer()\n",
    "\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=epochs,\n",
    "            validation_data=val_ds,\n",
    "            callbacks=callbacks,\n",
    "            initial_epoch=initial_epoch\n",
    "        )\n",
    "\n",
    "        benchmark.end_training_timer()\n",
    "\n",
    "        clear_memory()\n",
    "\n",
    "        print(\"\\nSaving final model...\")\n",
    "        final_model_path = os.path.join(MODELS_DIR, f'final_{model_name}.keras')\n",
    "        model.save(final_model_path)\n",
    "        print(f\"Final model saved to {final_model_path}\")\n",
    "\n",
    "        print(\"\\nMeasuring model performance...\")\n",
    "        benchmark.measure_inference_time(model, test_ds)\n",
    "        benchmark.measure_memory_usage()\n",
    "        benchmark.calculate_model_size(final_model_path)\n",
    "\n",
    "        print(\"\\nEvaluating on test set...\")\n",
    "        test_results = model.evaluate(test_ds, verbose=1)\n",
    "\n",
    "        cm, report = compute_confusion_matrix(model, test_ds)\n",
    "\n",
    "        benchmark.update_metrics(history, test_results, cm, report)\n",
    "        benchmark.save_metrics(BENCHMARK_DIR)\n",
    "\n",
    "        print(\"\\nGenerating plots...\")\n",
    "        plot_metrics(history)\n",
    "\n",
    "        return model, history, benchmark\n",
    "    except Exception as e:\n",
    "        print(f\"Error in training process: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742038283546,
     "user": {
      "displayName": "Md. Shifat Hasan",
      "userId": "07131367091968026409"
     },
     "user_tz": -360
    },
    "id": "9-XEy0POhcQZ"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"\\nTraining model with text features...\")\n",
    "    model_with_text, history_with_text, benchmark_with_text = train_model(\n",
    "        DATA_DIR, use_text=True, epochs=NUM_EPOCHS\n",
    "    )\n",
    "    print(\"\\nTraining model without text features...\")\n",
    "    model_without_text, history_without_text, benchmark_without_text = train_model(\n",
    "        DATA_DIR, use_text=False, epochs=NUM_EPOCHS\n",
    "    )\n",
    "\n",
    "    benchmark_with_text.plot_comparison(benchmark_without_text, BENCHMARK_DIR)\n",
    "\n",
    "    print(\"\\nModel Comparison Summary:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Metric':<30} {'With Text':<25} {'Without Text':<25}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    metrics = [\n",
    "        ('Accuracy', 'accuracy'),\n",
    "        ('Precision', 'precision'),\n",
    "        ('Recall', 'recall'),\n",
    "        ('AUC', 'auc'),\n",
    "        ('Training Time (s)', 'training_time'),\n",
    "        ('Inference Time (s)', 'inference_time'),\n",
    "        ('Model Size (MB)', 'model_size'),\n",
    "        ('Memory Usage (MB)', 'memory_usage')\n",
    "    ]\n",
    "\n",
    "    for metric_name, metric_key in metrics:\n",
    "        with_text = benchmark_with_text.metrics[metric_key]\n",
    "        without_text = benchmark_without_text.metrics[metric_key]\n",
    "        print(f\"{metric_name:<30} {with_text:<25.4f} {without_text:<25.4f}\")\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"\\nComparison plots saved to: {BENCHMARK_DIR}\")\n",
    "\n",
    "    return model_with_text, model_without_text, benchmark_with_text, benchmark_without_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OD6vXLtsjopN",
    "outputId": "b440b362-bc19-4103-adf7-eea5b0195d2a"
   },
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_model(model_path, image_paths, text_paths=None):\n",
    "    try:\n",
    "        use_text = text_paths is not None\n",
    "\n",
    "        print(f\"Loading model from {model_path}...\")\n",
    "        if not os.path.exists(model_path):\n",
    "            raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "\n",
    "        model = keras.models.load_model(model_path)\n",
    "        print(f\"Model loaded successfully\")\n",
    "\n",
    "        results = []\n",
    "\n",
    "        print(\"\\nPrediction Results:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Image':<30} {'Prediction':<20} {'Confidence':<20}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        for i, img_path in enumerate(image_paths):\n",
    "            try:\n",
    "                if not os.path.exists(img_path):\n",
    "                    print(f\"Warning: Image file not found: {img_path}\")\n",
    "                    continue\n",
    "\n",
    "                img = keras.utils.load_img(img_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "                img_array = keras.utils.img_to_array(img) / 255.0\n",
    "                img_array = preprocessing_model(np.expand_dims(img_array, 0))\n",
    "\n",
    "                if use_text and i < len(text_paths):\n",
    "                    if not os.path.exists(text_paths[i]):\n",
    "                        print(f\"Warning: Text file not found: {text_paths[i]}\")\n",
    "                        text_array = np.zeros((1, TEXT_MAX_LENGTH), dtype=np.int32)\n",
    "                    else:\n",
    "                        text_array = np.expand_dims(process_text(text_paths[i]), 0)\n",
    "                    predictions = model.predict([img_array, text_array], verbose=0)[0]\n",
    "                else:\n",
    "                    predictions = model.predict(img_array, verbose=0)[0]\n",
    "\n",
    "                pred_class = np.argmax(predictions)\n",
    "                confidence = predictions[pred_class] * 100\n",
    "\n",
    "                conf_bar_length = 20\n",
    "                filled_length = int(conf_bar_length * confidence / 100)\n",
    "                conf_bar = '█' * filled_length + '░' * (conf_bar_length - filled_length)\n",
    "\n",
    "                img_filename = os.path.basename(img_path)\n",
    "                if len(img_filename) > 25:\n",
    "                    img_filename = img_filename[:22] + \"...\"\n",
    "\n",
    "                pred_class_name = CLASS_NAMES[pred_class]\n",
    "\n",
    "                print(f\"{img_filename:<30} {pred_class_name:<20} {confidence:>6.2f}% {conf_bar}\")\n",
    "\n",
    "                result = {\n",
    "                    'image_path': img_path,\n",
    "                    'predicted_class': pred_class_name,\n",
    "                    'confidence': confidence,\n",
    "                    'class_probabilities': {CLASS_NAMES[i]: float(predictions[i]) for i in range(len(CLASS_NAMES))}\n",
    "                }\n",
    "\n",
    "                if use_text and i < len(text_paths):\n",
    "                    result['text_path'] = text_paths[i]\n",
    "\n",
    "                results.append(result)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {str(e)}\")\n",
    "                results.append({\n",
    "                    'image_path': img_path,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"Processed {len(results)} images\")\n",
    "\n",
    "        if results:\n",
    "            class_counts = {}\n",
    "            for result in results:\n",
    "                if 'predicted_class' in result:\n",
    "                    class_name = result['predicted_class']\n",
    "                    class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "\n",
    "            print(\"\\nPrediction Summary:\")\n",
    "            for class_name, count in class_counts.items():\n",
    "                percentage = (count / len(results)) * 100\n",
    "                print(f\"{class_name}: {count} images ({percentage:.1f}%)\")\n",
    "\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction process: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(model_path, data_dir, output_dir='../evaluation_results', use_text=True):\n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Load the model\n",
    "        print(\"Loading model...\")\n",
    "        model = keras.models.load_model(model_path)\n",
    "        \n",
    "        # Create datasets\n",
    "        train_ds = keras.utils.image_dataset_from_directory(\n",
    "            os.path.join(data_dir, 'train'),\n",
    "            labels='inferred',\n",
    "            label_mode='categorical',\n",
    "            class_names=CLASS_NAMES,\n",
    "            batch_size=32,\n",
    "            image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        test_ds = keras.utils.image_dataset_from_directory(\n",
    "            os.path.join(data_dir, 'test'),\n",
    "            labels='inferred',\n",
    "            label_mode='categorical',\n",
    "            class_names=CLASS_NAMES,\n",
    "            batch_size=32,\n",
    "            image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        def preprocess_data(images, labels):\n",
    "            images = tf.cast(images, tf.float32) / 255.0\n",
    "            mean = tf.constant([0.485, 0.456, 0.406])\n",
    "            std = tf.constant([0.229, 0.224, 0.225])\n",
    "            images = (images - mean) / std\n",
    "            if use_text:\n",
    "                # Add dummy text input (zeros) since we don't have actual text data\n",
    "                dummy_text = tf.zeros((tf.shape(images)[0], TEXT_MAX_LENGTH), dtype=tf.int32)\n",
    "                return (images, dummy_text), labels\n",
    "            return images, labels\n",
    "\n",
    "        train_ds = train_ds.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        test_ds = test_ds.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "        train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "        test_ds = test_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        print(\"\\nEvaluating on training set...\")\n",
    "        train_metrics = model.evaluate(train_ds, verbose=1)\n",
    "        print(\"\\nEvaluating on test set...\")\n",
    "        test_metrics = model.evaluate(test_ds, verbose=1)\n",
    "\n",
    "        print(\"\\nGenerating predictions for visualization...\")\n",
    "        train_pred, train_true = [], []\n",
    "        test_pred, test_true = [], []\n",
    "\n",
    "        for data, labels in train_ds:\n",
    "            if use_text:\n",
    "                images, text = data\n",
    "                pred = model.predict([images, text], verbose=0)\n",
    "            else:\n",
    "                pred = model.predict(data, verbose=0)\n",
    "            train_pred.extend(np.argmax(pred, axis=1))\n",
    "            train_true.extend(np.argmax(labels, axis=1))\n",
    "\n",
    "        for data, labels in test_ds:\n",
    "            if use_text:\n",
    "                images, text = data\n",
    "                pred = model.predict([images, text], verbose=0)\n",
    "            else:\n",
    "                pred = model.predict(data, verbose=0)\n",
    "            test_pred.extend(np.argmax(pred, axis=1))\n",
    "            test_true.extend(np.argmax(labels, axis=1))\n",
    "\n",
    "        train_cm = confusion_matrix(train_true, train_pred)\n",
    "        test_cm = confusion_matrix(test_true, test_pred)\n",
    "\n",
    "        train_report = classification_report(train_true, train_pred, \n",
    "                                          target_names=CLASS_NAMES, digits=4)\n",
    "        test_report = classification_report(test_true, test_pred,\n",
    "                                         target_names=CLASS_NAMES, digits=4)\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        train_display = ConfusionMatrixDisplay(\n",
    "            confusion_matrix=train_cm,\n",
    "            display_labels=CLASS_NAMES\n",
    "        )\n",
    "        train_display.plot(\n",
    "            cmap='Blues',\n",
    "            values_format='d',\n",
    "            xticks_rotation=45,\n",
    "            ax=plt.gca()\n",
    "        )\n",
    "        plt.title('Training Set Confusion Matrix', pad=20, size=14)\n",
    "        plt.grid(False)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        test_display = ConfusionMatrixDisplay(\n",
    "            confusion_matrix=test_cm,\n",
    "            display_labels=CLASS_NAMES\n",
    "        )\n",
    "        test_display.plot(\n",
    "            cmap='Blues',\n",
    "            values_format='d',\n",
    "            xticks_rotation=45,\n",
    "            ax=plt.gca()\n",
    "        )\n",
    "        plt.title('Test Set Confusion Matrix', pad=20, size=14)\n",
    "        plt.grid(False)\n",
    "        \n",
    "        plt.tight_layout(pad=3.0)\n",
    "        plt.savefig(os.path.join(output_dir, 'confusion_matrices.png'), \n",
    "                   bbox_inches='tight', \n",
    "                   dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        train_cm_normalized = train_cm.astype('float') / train_cm.sum(axis=1)[:, np.newaxis]\n",
    "        train_display = ConfusionMatrixDisplay(\n",
    "            confusion_matrix=train_cm_normalized,\n",
    "            display_labels=CLASS_NAMES\n",
    "        )\n",
    "        train_display.plot(\n",
    "            cmap='Blues',\n",
    "            values_format='.2%',\n",
    "            xticks_rotation=45,\n",
    "            ax=plt.gca()\n",
    "        )\n",
    "        plt.title('Training Set Normalized Confusion Matrix', pad=20, size=14)\n",
    "        plt.grid(False)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        test_cm_normalized = test_cm.astype('float') / test_cm.sum(axis=1)[:, np.newaxis]\n",
    "        test_display = ConfusionMatrixDisplay(\n",
    "            confusion_matrix=test_cm_normalized,\n",
    "            display_labels=CLASS_NAMES\n",
    "        )\n",
    "        test_display.plot(\n",
    "            cmap='Blues',\n",
    "            values_format='.2%',\n",
    "            xticks_rotation=45,\n",
    "            ax=plt.gca()\n",
    "        )\n",
    "        plt.title('Test Set Normalized Confusion Matrix', pad=20, size=14)\n",
    "        plt.grid(False)\n",
    "        \n",
    "        # Adjust layout and save\n",
    "        plt.tight_layout(pad=3.0)\n",
    "        plt.savefig(os.path.join(output_dir, 'confusion_matrices_normalized.png'), \n",
    "                   bbox_inches='tight', \n",
    "                   dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        metrics_dict = {\n",
    "            'training': {\n",
    "                'loss': float(train_metrics[0]),\n",
    "                'accuracy': float(train_metrics[1]),\n",
    "                'precision': float(train_metrics[2]),\n",
    "                'recall': float(train_metrics[3]),\n",
    "                'auc': float(train_metrics[4]),\n",
    "                'classification_report': train_report,\n",
    "                'confusion_matrix': train_cm.tolist()\n",
    "            },\n",
    "            'test': {\n",
    "                'loss': float(test_metrics[0]),\n",
    "                'accuracy': float(test_metrics[1]),\n",
    "                'precision': float(test_metrics[2]),\n",
    "                'recall': float(test_metrics[3]),\n",
    "                'auc': float(test_metrics[4]),\n",
    "                'classification_report': test_report,\n",
    "                'confusion_matrix': test_cm.tolist()\n",
    "            }\n",
    "        }\n",
    "\n",
    "        with open(os.path.join(output_dir, 'evaluation_metrics.json'), 'w') as f:\n",
    "            json.dump(metrics_dict, f, indent=4)\n",
    "\n",
    "        with open(os.path.join(output_dir, 'evaluation_report.txt'), 'w') as f:\n",
    "            f.write(\"Training Set Classification Report:\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\")\n",
    "            f.write(train_report)\n",
    "            f.write(\"\\n\\nTest Set Classification Report:\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\")\n",
    "            f.write(test_report)\n",
    "\n",
    "        print(\"\\nEvaluation Results Summary:\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Training Set Metrics:\")\n",
    "        print(f\"  Loss:      {metrics_dict['training']['loss']:.4f}\")\n",
    "        print(f\"  Accuracy:  {metrics_dict['training']['accuracy']:.4f}\")\n",
    "        print(f\"  Precision: {metrics_dict['training']['precision']:.4f}\")\n",
    "        print(f\"  Recall:    {metrics_dict['training']['recall']:.4f}\")\n",
    "        print(f\"  AUC:       {metrics_dict['training']['auc']:.4f}\")\n",
    "\n",
    "        print(\"\\nTest Set Metrics:\")\n",
    "        print(f\"  Loss:      {metrics_dict['test']['loss']:.4f}\")\n",
    "        print(f\"  Accuracy:  {metrics_dict['test']['accuracy']:.4f}\")\n",
    "        print(f\"  Precision: {metrics_dict['test']['precision']:.4f}\")\n",
    "        print(f\"  Recall:    {metrics_dict['test']['recall']:.4f}\")\n",
    "        print(f\"  AUC:       {metrics_dict['test']['auc']:.4f}\")\n",
    "\n",
    "        print(f\"\\nDetailed results saved to: {output_dir}\")\n",
    "        return metrics_dict\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in model evaluation: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model_performance(\n",
    "#     model_path='../Models/final_model_with_text.keras',\n",
    "#     data_dir='../Data',\n",
    "#     output_dir='../Metrics/Benchmarks/evaluation_results/image_with_text',\n",
    "#     use_text=True\n",
    "# )\n",
    "\n",
    "# evaluate_model_performance(\n",
    "#     model_path='../Models/final_model_without_text.keras',\n",
    "#     data_dir='../Data',\n",
    "#     output_dir='../Metrics/Benchmarks/evaluation_results/image_without_text',\n",
    "#     use_text=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
